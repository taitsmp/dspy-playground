{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dspy Intro\n",
    "\n",
    "#### Concepts\n",
    "\n",
    "* Signatures - tells you about the task at the input and output level.  Think about function signatures.\n",
    "* Predictors\n",
    "* Modules - a pipeline of LLM stuff (signature, predictor, etc.)\n",
    "* Optimizers / Teleprompters - make your pipeline \"trainable\".  Compiles your module and adjusts weights (or whatever is adjustable) from a trainingset and a \"metric\"\n",
    "\n",
    "More\n",
    "\n",
    "* Retriever\n",
    "* Learner\n",
    "* Metric\n",
    "  - think \"loss function\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "repo_path = '.'\n",
    "\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)\n",
    "\n",
    "# Set up the cache for this notebook\n",
    "os.environ[\"DSP_NOTEBOOK_CACHEDIR\"] = os.path.join(repo_path, 'cache')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: console dejavu events execute kernel kernelspec lab\n",
      "labextension labhub migrate nbconvert notebook qtconsole run server\n",
      "troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources # Install the package if it's not installed\n",
    "if not \"dspy-ai\" in {pkg.key for pkg in pkg_resources.working_set}:\n",
    "    !pip install -U pip\n",
    "    !pip install dspy-ai\n",
    "    !pip install openai~=0.28.1\n",
    "    # !pip install -e $repo_path\n",
    "\n",
    "import dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# Read the configuration file\n",
    "config.read('config.ini')\n",
    "\n",
    "# Access the API key\n",
    "api_key = config['openai']['api_key']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a hosted server with COLBERT that includes wikipedia extracts. We'll use it for the \"retriever model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo = dspy.OpenAI(model='gpt-3.5-turbo', api_key=api_key)\n",
    "colbertv2_wiki17_abstracts = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "dspy.settings.configure(lm=turbo, rm=colbertv2_wiki17_abstracts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Here's the response from GPT-3.5 Turbo:\n",
      "The capital of California is Sacramento.\n"
     ]
    }
   ],
   "source": [
    "# prove that openai is working\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Make a call to GPT-3.5 Turbo to test the API key\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the capital of California?\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(\"Success! Here's the response from GPT-3.5 Turbo:\")\n",
    "    print(response.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How DSPy programming works\n",
    "\n",
    "#### A word on the workflow\n",
    "\n",
    "You can build your own DSPy programs for various tasks, e.g., question answering, information extraction, or text-to-SQL.\n",
    "\n",
    "Whatever the task, the general workflow is:\n",
    "\n",
    "1. **Collect a little bit of data.** Define examples of the inputs and outputs of your program (e.g., questions and their answers). This could just be a handful of quick examples you wrote down. If large datasets exist, the more the merrier!\n",
    "1. **Write your program.** Define the modules (i.e., sub-tasks) of your program and the way they should interact together to solve your task.\n",
    "1. **Define some validation logic.** What makes for a good run of your program? Maybe the answers need to have a certain length or stick to a particular format? Specify the logic that checks that.\n",
    "1. **Compile!** Ask DSPy to compile your program using your data. The compiler will use your data and validation logic to optimize your program (e.g., prompts and modules) so it's efficient and effective!\n",
    "1. **Iterate.** Repeat the process by improving your data, program, validation, or by using more advanced features of the DSPy compiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taitlarson/.pyenv/versions/3.11.8/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.datasets import HotPotQA\n",
    "\n",
    "# Load the dataset.\n",
    "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0)\n",
    "\n",
    "# Tell DSPy that the 'question' field is the input. Any other fields are labels and/or metadata.\n",
    "trainset = [x.with_inputs('question') for x in dataset.train]\n",
    "devset = [x.with_inputs('question') for x in dataset.dev]\n",
    "\n",
    "len(trainset), len(devset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSPy typically requires very minimal labeling. Whereas your pipeline may involve six or seven complex steps, **you only need labels for the initial question and the final answer**. DSPy will bootstrap any intermediate labels needed to support your pipeline. If you change your pipeline in any way, the data bootstrapped will change accordingly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n"
     ]
    }
   ],
   "source": [
    "train_example = trainset[0]\n",
    "print(f\"Question: {train_example.question}\")\n",
    "print(f\"Answer: {train_example.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples in the dev set contain a third field, namely, `titles` of relevant Wikipedia articles. This is not essential but, for the sake of this intro, it'll help us get a sense of how well our programs are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n",
      "Answer: English\n",
      "Relevant Wikipedia Titles: {'Restaurant: Impossible', 'Robert Irvine'}\n"
     ]
    }
   ],
   "source": [
    "dev_example = devset[18]\n",
    "print(f\"Question: {dev_example.question}\")\n",
    "print(f\"Answer: {dev_example.answer}\")\n",
    "print(f\"Relevant Wikipedia Titles: {dev_example.gold_titles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring labels and valid outputs\n",
    "\n",
    "After loading the raw data, we'd applied x.with_inputs('question') to each example to tell DSPy that our input field in each example will be just `question`. Any other fields are labels or metadata that are not given to the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this dataset, training examples have input keys ['question'] and label keys ['answer']\n",
      "For this dataset, dev examples have input keys ['question'] and label keys ['answer', 'gold_titles']\n"
     ]
    }
   ],
   "source": [
    "print(f\"For this dataset, training examples have input keys {train_example.inputs().keys()} and label keys {train_example.labels().keys()}\")\n",
    "print(f\"For this dataset, dev examples have input keys {dev_example.inputs().keys()} and label keys {dev_example.labels().keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DSPy, we will maintain a clean separation between defining your modules in a **declarative way** and calling them in a **pipeline** to solve the task.\n",
    "\n",
    "## Signatures\n",
    "\n",
    "Every call to the LM in a DSPy program needs to have a Signature.\n",
    "\n",
    "A signature consists of three simple elements:\n",
    "\n",
    "* A minimal description of the **sub-task** the LM is supposed to solve.\n",
    "* A description of one or more **input fields** (e.g., input question) that will we will give to the LM.\n",
    "* A description of one or more **output fields** (e.g., the question's answer) that we will expect from the LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `BasicQA`, the docstring describes the sub-task here (i.e., answering questions). Each `InputField` or `OutputField` can optionally contain a description `desc` too. When it's not given, it's inferred from the field's name (e.g., `question`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictors\n",
    "\n",
    "A predictor is a module that knows how to use the LM to implement a signature. Importantly, predictors can **learn** to fit their behavior to the task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n",
      "Predicted Answer: American\n"
     ]
    }
   ],
   "source": [
    "# Define the predictor\n",
    "generate_answer = dspy.Predict(BasicQA)\n",
    "\n",
    "# call the predictor on some input\n",
    "pred = generate_answer(question=dev_example.question)\n",
    "\n",
    "# Print the input and the prediction.\n",
    "print(f\"Question: {dev_example.question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n",
      "Answer:\u001b[32m American\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "turbo.inspect_history(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Chain Of Thought so that\n",
    "\n",
    "* we can see how the model reasons\n",
    "* the model hopefully produces better output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cot = dspy.ChainOfThought(BasicQA)\n",
    "pred = gen_cot(question=dev_example.question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n",
      "Thought: We know that the chef and restaurateur featured in Restaurant: Impossible is British.\n",
      "Predicted Answer: British\n"
     ]
    }
   ],
   "source": [
    "# Print the input, the chain of thought, and the prediction.\n",
    "print(f\"Question: {dev_example.question}\")\n",
    "print(f\"Thought: {pred.rationale.split('.', 1)[1].strip()}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dspy.predict.chain_of_thought.ChainOfThought"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a \"predictor\"\n",
    "type(gen_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve = dspy.Retrieve(k=3) #must use what was setup in dspy.settings.configure\n",
    "topK_passages = retrieve(dev_example.question).passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 passages for question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible? \n",
      " ------------------------------ \n",
      "\n",
      "1] Restaurant: Impossible | Restaurant: Impossible is an American reality television series, featuring chef and restaurateur Robert Irvine, that aired on Food Network from 2011 to 2016. \n",
      "\n",
      "2] Jean Joho | Jean Joho is a French-American chef and restaurateur. He is chef/proprietor of Everest in Chicago (founded in 1986), Paris Club Bistro & Bar and Studio Paris in Chicago, The Eiffel Tower Restaurant in Las Vegas, and Brasserie JO in Boston. \n",
      "\n",
      "3] List of Restaurant: Impossible episodes | This is the list of the episodes for the American cooking and reality television series \"Restaurant Impossible\", produced by Food Network. The premise of the series is that within two days and on a budget of $10,000, celebrity chef Robert Irvine renovates a failing American restaurant with the goal of helping to restore it to profitability and prominence. Irvine is assisted by a designer (usually Taniya Nayak, Cheryl Torrenueva, or Lynn Keagan, but sometimes Vanessa De Leon, Krista Watterworth, Yvette Irene, or Nicole Faccuito), along with general contractor Tom Bury, who sometimes does double duty as both general contractor and designer. After assessing the problems with the restaurant, Robert Irvine typically creates a plan for the new decor, oversees the cleaning of the restaurant, reduces the size of the menu and improves the food, develops a promotional activity, educates the restaurant's owners, or trains the staff, as needed by each restaurant. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Top {retrieve.k} passages for question: {dev_example.question} \\n\", '-' * 30, '\\n')\n",
    "\n",
    "for idx, passage in enumerate(topK_passages):\n",
    "    print(f'{idx+1}]', passage, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "topK_passages_2 = retrieve(devset[5].question).passages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 passages for question: The Newark Airport Exchange is at the northern edge of an airport that is operated by whom? \n",
      " ------------------------------ \n",
      "\n",
      "1] Newark Airport Interchange | The Newark Airport Interchange is a massive interchange of Interstate 78, U.S. Route 1-9, U.S. Route 22, New Jersey Route 21, and Interstate 95 (the New Jersey Turnpike) at the northern edge of Newark Liberty International Airport in Newark, New Jersey. \n",
      "\n",
      "2] Newark Liberty International Airport | Newark Liberty International Airport (IATA: EWR, ICAO: KEWR, FAA LID: EWR) , originally Newark Metropolitan Airport and later Newark International Airport, is the primary airport serving the U.S. state of New Jersey. The airport straddles the boundary between the cities of Elizabeth and Newark, the latter of which is the most populous city in the state. The airport is owned jointly by the cities of Elizabeth and Newark and leased to and operated by the Port Authority of New York and New Jersey. \n",
      "\n",
      "3] Newark Liberty International Airport Station | Newark Liberty International Airport Station (also known as Newark International Airport Station) is a railroad station on the Northeast Corridor (NEC) in Newark, New Jersey. The station provides access to Newark Liberty International Airport (EWR) via the AirTrain monorail which connects the station to the airport's terminals and parking areas. It is served by New Jersey Transit's (NJT) Northeast Corridor Line and North Jersey Coast Line and Amtrak's \"Northeast Regional\" and Keystone Service trains. The station, located in the Dayton neighborhood of the city, has no pedestrian access, bus service, parking facility, or drop-off area. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Top {retrieve.k} passages for question: {devset[5].question} \\n\", '-' * 30, '\\n')\n",
    "\n",
    "for idx, passage in enumerate(topK_passages_2):\n",
    "    print(f'{idx+1}]', passage, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'History of the FIFA World Cup | The FIFA World Cup was first held in 1930, when FIFA president Jules Rimet decided to stage an international football tournament. The inaugural edition, held in 1930, was contested as a final tournament of only thirteen teams invited by the organization. Since then, the World Cup has experienced successive expansions and format remodeling to its current 32-team final tournament preceded by a two-year qualifying process, involving over 200 teams from around the world.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# faster experience\n",
    "retrieve(\"When was the first FIFA World Cup held?\").passages[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG\n",
    "\n",
    "We'll build a retrieval-augmented pipeline for answer generation.\n",
    "\n",
    "Given a question, we'll search for the top-3 passages in Wikipedia and then feed them as context for answer generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "class RAG(dspy.Module):\n",
    "\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.Predict(GenerateAnswer) #creates a predictor \n",
    "\n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teleprompter\n",
    "\n",
    "Let's build a pipeline we run \"train\" (or optimize using a teleprompter)\n",
    "\n",
    "**Teleprompters:** Teleprompters are powerful optimizers that can take any program and learn to bootstrap and select effective prompts for its modules. Hence the name, which means \"prompting at a distance\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cache/compiler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:00<00:00, 878.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# Validation logic: check that the predicted answer is correct.\n",
    "# Also check that the retrieved context does actually contain that answer.\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "    return answer_EM and answer_PM\n",
    "\n",
    "# Set up a basic teleprompter, which will compile our RAG program.\n",
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer)\n",
    "\n",
    "# Compile!\n",
    "compiled_rag = teleprompter.compile(RAG(), trainset=trainset) #takes our RAG module and the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What fruit native to new england is harvested in the fall?\n",
      "Predicted Answer: McIntosh Apple\n",
      "Retrieved Contexts (truncated): ['Leaf peeping | Leaf peeping is an informal term in the United States for the activity in which people travel to view and photograph the fall foliage in areas where leaves change colors in autumn, part...', 'McIntosh (apple) | The McIntosh ( ), McIntosh Red, or colloquially the Mac is an apple cultivar, the national apple of Canada. The fruit has red and green skin, a tart flavour, and tender white flesh,...', 'Eucalyptus campanulata | Eucalyptus campanulata, known as the New England blackbutt, or gum-topped peppermint is a tree native to eastern Australia. Previously known as Eucalyptus andrewsii subsp. cam...']\n"
     ]
    }
   ],
   "source": [
    "# Ask any question you like to this simple RAG program.\n",
    "my_question = \"What fruit native to new england is harvested in the fall?\"\n",
    "\n",
    "# Get the prediction. This contains `pred.context` and `pred.answer`.\n",
    "pred = compiled_rag(my_question)\n",
    "\n",
    "# Print the contexts and the answer.\n",
    "print(f\"Question: {my_question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers\n",
      "\n",
      "---\n",
      "\n",
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n",
      "\n",
      "Question: \"Everything Has Changed\" is a song from an album released under which record label ?\n",
      "Answer: Big Machine Records\n",
      "\n",
      "Question: In what year was the club founded that played Manchester City in the 1972 FA Charity Shield\n",
      "Answer: 1874\n",
      "\n",
      "Question: Which Pakistani cricket umpire who won 3 consecutive ICC umpire of the year awards in 2009, 2010, and 2011 will be in the ICC World Twenty20?\n",
      "Answer: Aleem Sarwar Dar\n",
      "\n",
      "Question: Having the combination of excellent foot speed and bat speed helped Eric Davis, create what kind of outfield for the Los Angeles Dodgers?\n",
      "Answer: \"Outfield of Dreams\"\n",
      "\n",
      "Question: Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?\n",
      "Answer: Aleksandr Danilovich Aleksandrov\n",
      "\n",
      "Question: The Organisation that allows a community to influence their operation or use and to enjoy the benefits arisingwas founded in what year?\n",
      "Answer: 2010\n",
      "\n",
      "Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?\n",
      "Answer: Kerry Condon\n",
      "\n",
      "Question: Which is taller, the Empire State Building or the Bank of America Tower?\n",
      "Answer: The Empire State Building\n",
      "\n",
      "Question: Which of these publications was most recently published, Who Put the Bomp or Self?\n",
      "Answer: Self\n",
      "\n",
      "Question: Tombstone stared an actor born May 17, 1955 known as who?\n",
      "Answer: Bill Paxton\n",
      "\n",
      "Question: Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?\n",
      "Answer: Buena Vista Distribution\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "Question: ${question}\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «Candace Kita | Kita's first role was as a news anchor in the 1991 movie \"Stealth Hunters\". Kita's first recurring television role was in Fox's \"Masked Rider\", from 1995 to 1996. She appeared as a series regular lead in all 40 episodes. Kita also portrayed a frantic stewardess in a music video directed by Mark Pellington for the British group, Catherine Wheel, titled, \"Waydown\" in 1995. In 1996, Kita also appeared in the film \"Barb Wire\" (1996) and guest starred on \"The Wayans Bros.\". She also guest starred in \"Miriam Teitelbaum: Homicide\" with \"Saturday Night Live\" alumni Nora Dunn, \"Wall To Wall Records\" with Jordan Bridges, \"Even Stevens\", \"Felicity\" with Keri Russell, \"V.I.P.\" with Pamela Anderson, \"Girlfriends\", \"The Sweet Spot\" with Bill Murray, and \"Movies at Our House\". She also had recurring roles on the FX spoof, \"Son of the Beach\" from 2001 to 2002, ABC-Family's \"Dance Fever\" and Oxygen Network's \"Running with Scissors\". Kita also appeared in the films \"Little Heroes\" (2002) and \"Rennie's Landing\" (2001).»\n",
      "[2] «Jilly Kitzinger | Jilly Kitzinger is a fictional character in the science fiction series \"Torchwood\", portrayed by American actress Lauren Ambrose. The character was promoted as one of five new main characters to join \"Torchwood\" in its fourth series, \"\" (2011), as part of a new co-production between \"Torchwood\"' s British network, BBC One, and its American financiers on US premium television network Starz. Ambrose appears in seven of the ten episodes, and is credited as a \"special guest star\" throughout. Whilst reaction to the serial was mixed, Ambrose' portrayal was often singled out by critics for particular praise and in 2012 she received a Saturn Award nomination for Best Supporting Actress on Television.»\n",
      "[3] «Candace Brown | Candace June Brown (born June 15, 1980) is an American actress and comedian best known for her work on shows such as \"Grey's Anatomy\", \"Desperate Housewives\", \"Head Case\", The \"Wizards Of Waverly Place\". In 2011, she joined the guest cast for \"Torchwood\"' s fourth series' \"\", airing on BBC One in the United Kingdom and premium television network Starz.»\n",
      "Question: which American actor was Candace Kita guest starred with\n",
      "Answer: Bill Murray\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «Tae Kwon Do Times | Tae Kwon Do Times is a magazine devoted to the martial art of taekwondo, and is published in the United States of America. While the title suggests that it focuses on taekwondo exclusively, the magazine also covers other Korean martial arts. \"Tae Kwon Do Times\" has published articles by a wide range of authors, including He-Young Kimm, Thomas Kurz, Scott Shaw, and Mark Van Schuyver.»\n",
      "[2] «Kwon Tae-man | Kwon Tae-man (born 1941) was an early Korean hapkido practitioner and a pioneer of the art, first in Korea and then in the United States. He formed one of the earliest dojang's for hapkido in the United States in Torrance, California, and has been featured in many magazine articles promoting the art.»\n",
      "[3] «Hee Il Cho | Cho Hee Il (born October 13, 1940) is a prominent Korean-American master of taekwondo, holding the rank of 9th \"dan\" in the martial art. He has written 11 martial art books, produced 70 martial art training videos, and has appeared on more than 70 martial arts magazine covers. Cho won several national and international competitions as a taekwondo competitor, and has appeared in several films, including \"Fight to Win\", \"Best of the Best\", \"Bloodsport II\", and \"Bloodsport III\". He founded the Action International Martial Arts Association (AIMAA) in 1980, and is its President. Cho is a member of both \"Black Belt\" magazine's Hall of Fame and \"Tae Kwon Do Times\" magazine's Hall of Fame.»\n",
      "Question: Which magazine has published articles by Scott Shaw, Tae Kwon Do Times or Southwest Art?\n",
      "Answer: Tae Kwon Do Times\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «Rosario Dawson | Rosario Isabel Dawson (born May 9, 1979) is an American actress, producer, singer, comic book writer, and political activist. She made her film debut in the 1995 teen drama \"Kids\". Her subsequent film roles include \"He Got Game\", \"Men in Black II\", \"25th Hour\", \"Rent\", \"Sin City\", \"Death Proof\", \"Seven Pounds\", \"\", and \"Top Five\". Dawson has also provided voice-over work for Disney and DC.»\n",
      "[2] «Sarai Gonzalez | Sarai Isaura Gonzalez (born 2005) is an American Latina child actress who made her professional debut at the age of 11 on the Spanish-language \"\"Soy Yo\"\" (\"That's Me\") music video by Bomba Estéreo. Cast as a \"nerdy\" tween with a \"sassy\" and \"confident\" attitude, her performance turned her into a \"Latina icon\" for \"female empowerment, identity and self-worth\". She subsequently appeared in two get out the vote videos for Latinos in advance of the 2016 United States elections.»\n",
      "[3] «Gabriela (2001 film) | Gabriela is a 2001 American romance film, starring Seidy Lopez in the title role alongside Jaime Gomez as her admirer Mike. The film has been cited as an inspiration behind the Premiere Weekend Club, which supports Latino film-making.»\n",
      "Question: Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?\n",
      "Answer: Rosario Dawson\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «Battle of Kursk | The Battle of Kursk was a Second World War engagement between German and Soviet forces on the Eastern Front near Kursk (450 km south-west of Moscow) in the Soviet Union during July and August 1943. The battle began with the launch of the German offensive, Operation Citadel (German: \"Unternehmen Zitadelle\" ), on 5 July, which had the objective of pinching off the Kursk salient with attacks on the base of the salient from north and south simultaneously. After the German offensive stalled on the northern side of the salient, on 12 July the Soviets commenced their Kursk Strategic Offensive Operation with the launch of Operation Kutuzov (Russian: Кутузов ) against the rear of the German forces in the northern side. On the southern side, the Soviets also launched powerful counterattacks the same day, one of which led to a large armoured clash, the Battle of Prokhorovka. On 3 August, the Soviets began the second phase of the Kursk Strategic Offensive Operation with the launch of Operation Polkovodets Rumyantsev (Russian: Полководец Румянцев ) against the German forces in the southern side of the Kursk salient.»\n",
      "[2] «Operation Mars | Operation Mars, also known as the Second Rzhev-Sychevka Offensive Operation (Russian: Вторая Ржевско-Сычёвская наступательная операция), was the codename for an offensive launched by Soviet forces against German forces during World War II. It took place between 25 November and 20 December 1942 around the Rzhev salient in the vicinity of Moscow.»\n",
      "[3] «Kholm Pocket | The Kholm Pocket (German: \"Kessel von Cholm\" ; Russian: Холмский котёл ) was the name given for the encirclement of German troops by the Red Army around Kholm south of Leningrad, during World War II on the Eastern Front, from 23 January 1942 until 5 May 1942. A much larger pocket was simultaneously surrounded in Demyansk, about 100 km to the northeast. These were the results of German retreat following their defeat during the Battle of Moscow.»\n",
      "Question: What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?\n",
      "Answer: Operation Citadel\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «Leaf peeping | Leaf peeping is an informal term in the United States for the activity in which people travel to view and photograph the fall foliage in areas where leaves change colors in autumn, particularly in New England. The origin of the term \"leaf peeping\" is not well known.»\n",
      "[2] «McIntosh (apple) | The McIntosh ( ), McIntosh Red, or colloquially the Mac is an apple cultivar, the national apple of Canada. The fruit has red and green skin, a tart flavour, and tender white flesh, which ripens in late September. In the 20th century it was the most popular cultivar in Eastern Canada and New England, and is considered an all-purpose apple, suitable both for cooking and eating raw. Apple Inc. employee Jef Raskin named the Macintosh line of personal computers after the fruit.»\n",
      "[3] «Eucalyptus campanulata | Eucalyptus campanulata, known as the New England blackbutt, or gum-topped peppermint is a tree native to eastern Australia. Previously known as Eucalyptus andrewsii subsp. campanulata, it differs from Eucalyptus andrewsii because of the fruit shape. Gumnuts being bell shaped (campanulate), pear shaped or obconical.»\n",
      "Question: What fruit native to new england is harvested in the fall?\n",
      "Answer:\u001b[32m McIntosh Apple\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "turbo.inspect_history(n=1)\n",
    "\n",
    "# My response doesn't include \"reasoning\".  the one online does. not sure why. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the compiled RAG program\n",
    "\n",
    "* this is kind of like looking at the weights in a LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_answer\n",
      "Example({'augmented': True, 'context': ['Candace Kita | Kita\\'s first role was as a news anchor in the 1991 movie \"Stealth Hunters\". Kita\\'s first recurring television role was in Fox\\'s \"Masked Rider\", from 1995 to 1996. She appeared as a series regular lead in all 40 episodes. Kita also portrayed a frantic stewardess in a music video directed by Mark Pellington for the British group, Catherine Wheel, titled, \"Waydown\" in 1995. In 1996, Kita also appeared in the film \"Barb Wire\" (1996) and guest starred on \"The Wayans Bros.\". She also guest starred in \"Miriam Teitelbaum: Homicide\" with \"Saturday Night Live\" alumni Nora Dunn, \"Wall To Wall Records\" with Jordan Bridges, \"Even Stevens\", \"Felicity\" with Keri Russell, \"V.I.P.\" with Pamela Anderson, \"Girlfriends\", \"The Sweet Spot\" with Bill Murray, and \"Movies at Our House\". She also had recurring roles on the FX spoof, \"Son of the Beach\" from 2001 to 2002, ABC-Family\\'s \"Dance Fever\" and Oxygen Network\\'s \"Running with Scissors\". Kita also appeared in the films \"Little Heroes\" (2002) and \"Rennie\\'s Landing\" (2001).', 'Jilly Kitzinger | Jilly Kitzinger is a fictional character in the science fiction series \"Torchwood\", portrayed by American actress Lauren Ambrose. The character was promoted as one of five new main characters to join \"Torchwood\" in its fourth series, \"\" (2011), as part of a new co-production between \"Torchwood\"\\' s British network, BBC One, and its American financiers on US premium television network Starz. Ambrose appears in seven of the ten episodes, and is credited as a \"special guest star\" throughout. Whilst reaction to the serial was mixed, Ambrose\\' portrayal was often singled out by critics for particular praise and in 2012 she received a Saturn Award nomination for Best Supporting Actress on Television.', 'Candace Brown | Candace June Brown (born June 15, 1980) is an American actress and comedian best known for her work on shows such as \"Grey\\'s Anatomy\", \"Desperate Housewives\", \"Head Case\", The \"Wizards Of Waverly Place\". In 2011, she joined the guest cast for \"Torchwood\"\\' s fourth series\\' \"\", airing on BBC One in the United Kingdom and premium television network Starz.'], 'question': 'which  American actor was Candace Kita  guest starred with ', 'answer': 'Bill Murray'}) (input_keys=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in compiled_rag.named_predictors():\n",
    "    print(name)\n",
    "    print(parameter.demos[0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate your Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 9  (66.7):  16%|█▌        | 8/50 [00:00<00:00, 545.96it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 50  (48.0): 100%|██████████| 50/50 [00:00<00:00, 712.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 50  (48.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/taitlarson/.pyenv/versions/3.11.8/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:142: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_36f49 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_36f49 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_36f49_row0_col0, #T_36f49_row0_col1, #T_36f49_row0_col2, #T_36f49_row0_col3, #T_36f49_row0_col4, #T_36f49_row0_col5, #T_36f49_row1_col0, #T_36f49_row1_col1, #T_36f49_row1_col2, #T_36f49_row1_col3, #T_36f49_row1_col4, #T_36f49_row1_col5, #T_36f49_row2_col0, #T_36f49_row2_col1, #T_36f49_row2_col2, #T_36f49_row2_col3, #T_36f49_row2_col4, #T_36f49_row2_col5, #T_36f49_row3_col0, #T_36f49_row3_col1, #T_36f49_row3_col2, #T_36f49_row3_col3, #T_36f49_row3_col4, #T_36f49_row3_col5, #T_36f49_row4_col0, #T_36f49_row4_col1, #T_36f49_row4_col2, #T_36f49_row4_col3, #T_36f49_row4_col4, #T_36f49_row4_col5 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_36f49\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_36f49_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_36f49_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_36f49_level0_col2\" class=\"col_heading level0 col2\" >gold_titles</th>\n",
       "      <th id=\"T_36f49_level0_col3\" class=\"col_heading level0 col3\" >context</th>\n",
       "      <th id=\"T_36f49_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_36f49_level0_col5\" class=\"col_heading level0 col5\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_36f49_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_36f49_row0_col0\" class=\"data row0 col0\" >Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
       "      <td id=\"T_36f49_row0_col1\" class=\"data row0 col1\" >no</td>\n",
       "      <td id=\"T_36f49_row0_col2\" class=\"data row0 col2\" >{'Cangzhou', 'Qionghai'}</td>\n",
       "      <td id=\"T_36f49_row0_col3\" class=\"data row0 col3\" >['Cangzhou | Cangzhou () is a prefecture-level city in eastern Hebei province, People\\'s Republic of China. At the 2010 census, Cangzhou\\'s built-up (\"or metro\") area...</td>\n",
       "      <td id=\"T_36f49_row0_col4\" class=\"data row0 col4\" >No</td>\n",
       "      <td id=\"T_36f49_row0_col5\" class=\"data row0 col5\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_36f49_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_36f49_row1_col0\" class=\"data row1 col0\" >Who conducts the draft in which Marc-Andre Fleury was drafted to the Vegas Golden Knights for the 2017-18 season?</td>\n",
       "      <td id=\"T_36f49_row1_col1\" class=\"data row1 col1\" >National Hockey League</td>\n",
       "      <td id=\"T_36f49_row1_col2\" class=\"data row1 col2\" >{'2017 NHL Expansion Draft', '2017–18 Pittsburgh Penguins season'}</td>\n",
       "      <td id=\"T_36f49_row1_col3\" class=\"data row1 col3\" >['2017–18 Pittsburgh Penguins season | The 2017–18 Pittsburgh Penguins season will be the 51st season for the National Hockey League ice hockey team that was...</td>\n",
       "      <td id=\"T_36f49_row1_col4\" class=\"data row1 col4\" >National Hockey League</td>\n",
       "      <td id=\"T_36f49_row1_col5\" class=\"data row1 col5\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_36f49_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_36f49_row2_col0\" class=\"data row2 col0\" >The Wings entered a new era, following the retirement of which Canadian retired professional ice hockey player and current general manager of the Tampa Bay...</td>\n",
       "      <td id=\"T_36f49_row2_col1\" class=\"data row2 col1\" >Steve Yzerman</td>\n",
       "      <td id=\"T_36f49_row2_col2\" class=\"data row2 col2\" >{'Steve Yzerman', '2006–07 Detroit Red Wings season'}</td>\n",
       "      <td id=\"T_36f49_row2_col3\" class=\"data row2 col3\" >['Steve Yzerman | Stephen Gregory \"Steve\" Yzerman ( ; born May 9, 1965) is a Canadian retired professional ice hockey player and current general manager...</td>\n",
       "      <td id=\"T_36f49_row2_col4\" class=\"data row2 col4\" >Steve Yzerman</td>\n",
       "      <td id=\"T_36f49_row2_col5\" class=\"data row2 col5\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_36f49_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_36f49_row3_col0\" class=\"data row3 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
       "      <td id=\"T_36f49_row3_col1\" class=\"data row3 col1\" >the River Tyne</td>\n",
       "      <td id=\"T_36f49_row3_col2\" class=\"data row3 col2\" >{'Crichton Castle', 'Crichton Collegiate Church'}</td>\n",
       "      <td id=\"T_36f49_row3_col3\" class=\"data row3 col3\" >[\"Crichton Collegiate Church | Crichton Collegiate Church is situated about 0.6 mi south west of the hamlet of Crichton in Midlothian, Scotland. Crichton itself is...</td>\n",
       "      <td id=\"T_36f49_row3_col4\" class=\"data row3 col4\" >River Tyne</td>\n",
       "      <td id=\"T_36f49_row3_col5\" class=\"data row3 col5\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_36f49_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_36f49_row4_col0\" class=\"data row4 col0\" >In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?</td>\n",
       "      <td id=\"T_36f49_row4_col1\" class=\"data row4 col1\" >King Alfred the Great</td>\n",
       "      <td id=\"T_36f49_row4_col2\" class=\"data row4 col2\" >{'Æthelweard (son of Alfred)', 'Ealhswith'}</td>\n",
       "      <td id=\"T_36f49_row4_col3\" class=\"data row4 col3\" >[\"Æthelweard of East Anglia | Æthelweard (died 854) was a 9th-century king of East Anglia, the long-lived Anglo-Saxon kingdom which today includes the English counties...</td>\n",
       "      <td id=\"T_36f49_row4_col4\" class=\"data row4 col4\" >Alfred the Great</td>\n",
       "      <td id=\"T_36f49_row4_col5\" class=\"data row4 col5\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1258ef910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center; \n",
       "                    font-size: 16px; \n",
       "                    font-weight: bold; \n",
       "                    color: #555; \n",
       "                    margin: 10px 0;'>\n",
       "                    ... 45 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "48.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "eval_on_hotpot = Evaluate(devset=devset, num_threads=1, display_progress=True, display_table=5)\n",
    "\n",
    "metric = dspy.evaluate.answer_exact_match\n",
    "eval_on_hotpot(compiled_rag, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm skipping evaluating retrieval. You can evaluate retrieval and compare to the entire pipeline.  If Retrieval eval is super low that tells you the LLM is getting the anwswers from it's weigh (memory).  \n",
    "\n",
    "Obviously, you don't use exact match as a metric for retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Hop Search (“Baleen”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.utils import deduplicate\n",
    "\n",
    "class GenerateSearchQuery(dspy.Signature):\n",
    "    \"\"\"Write a simple search query that will help answer a complex question\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    query = dspy.OutputField()\n",
    "\n",
    "\n",
    "class SimplifiedBaleen(dspy.Module):\n",
    "    def __init__(self, passages_per_hop=3, max_hops=2):\n",
    "        self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n",
    "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
    "        # GenerateAnswer is defined above as: context, querstion -> answer\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "        self.max_hops = max_hops\n",
    "\n",
    "    def forward(self, question):\n",
    "\n",
    "        context = []\n",
    "        for hop in range(self.max_hops):\n",
    "            query = self.generate_query[hop](context=context, question=question).query #note that 'context', 'question' and 'query' are all in the signature.\n",
    "            passages = self.retrieve(query).passages\n",
    "            context = deduplicate(context + passages)\n",
    "\n",
    "        pred = self.generate_answer(context=context, question=question).answer\n",
    "        return dspy.Prediction(context=context, answer=pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot and uncompiled Balean\n",
    "\n",
    "should work fine if your model is really smart. Won't work great for novel domains.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"How many storeys are in the castle that David Gregory inherited?\"\n",
    "uncompiled_b = SimplifiedBaleen()\n",
    "pred = uncompiled_b(my_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many storeys are in the castle that David Gregory inherited?\n",
      "Predicted Answer: five\n",
      "Retrieved Contexts (truncated): ['David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinn...', 'St. Gregory Hotel | The St. Gregory Hotel is a boutique hotel located in downtown Washington, D.C., in the United States. Established in 2000, the nine-floor hotel has 155 rooms, which includes 54 del...', 'Karl D. Gregory Cooperative House | Karl D. Gregory Cooperative House is a member of the Inter-Cooperative Council at the University of Michigan. The structure that stands at 1617 Washtenaw was origin...', 'Kinnairdy Castle | Kinnairdy Castle is a tower house, having five storeys and a garret, two miles south of Aberchirder, Aberdeenshire, Scotland. The alternative name is Old Kinnairdy....', 'Kinnordy House | Kinnordy House (alternative spellings: Kynnordy, Kinardy, Kinnordie and Kinorde) is an estate house near Kirriemuir in Angus, Scotland. The first house was built in the 1680s, when In...']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question: {my_question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Write a simple search query that will help answer a complex question\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the query}. We ...\n",
      "\n",
      "Query: ${query}\n",
      "\n",
      "---\n",
      "\n",
      "Context: N/A\n",
      "\n",
      "Question: How many storeys are in the castle that David Gregory inherited?\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the query. We know that David Gregory inherited a castle, so we need to find information on the number of storeys in that specific castle.\n",
      "\n",
      "Query: \"Number of storeys in castle inherited by David Gregory\"\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Write a simple search query that will help answer a complex question\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the query}. We ...\n",
      "\n",
      "Query: ${query}\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory's use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.»\n",
      "[2] «St. Gregory Hotel | The St. Gregory Hotel is a boutique hotel located in downtown Washington, D.C., in the United States. Established in 2000, the nine-floor hotel has 155 rooms, which includes 54 deluxe rooms, 85 suites with kitchens, and 16 top-floor suites with balconies. The hotel, which changed hands in June 2015, has a life-size statue of Marilyn Monroe in the lobby.»\n",
      "[3] «Karl D. Gregory Cooperative House | Karl D. Gregory Cooperative House is a member of the Inter-Cooperative Council at the University of Michigan. The structure that stands at 1617 Washtenaw was originally built in 1909 for the Tau Gamma Nu fraternity, but was purchased by the ICC in 1995. Gregory House is the only house in the organization that is expressly substance free. No tobacco, alcohol, or illicit drugs are allowed on the property. Gregory House has a maximum capacity of 29 members (by way of 13 single and 8 double capacity rooms) as of June 2008.»\n",
      "\n",
      "Question: How many storeys are in the castle that David Gregory inherited?\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the query. We know that David Gregory inherited Kinnairdy Castle in 1664. To find out how many storeys the castle has, we need to search for information on the castle's structure.\n",
      "\n",
      "Query: Number of storeys in Kinnairdy Castle David Gregory\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory's use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.»\n",
      "[2] «St. Gregory Hotel | The St. Gregory Hotel is a boutique hotel located in downtown Washington, D.C., in the United States. Established in 2000, the nine-floor hotel has 155 rooms, which includes 54 deluxe rooms, 85 suites with kitchens, and 16 top-floor suites with balconies. The hotel, which changed hands in June 2015, has a life-size statue of Marilyn Monroe in the lobby.»\n",
      "[3] «Karl D. Gregory Cooperative House | Karl D. Gregory Cooperative House is a member of the Inter-Cooperative Council at the University of Michigan. The structure that stands at 1617 Washtenaw was originally built in 1909 for the Tau Gamma Nu fraternity, but was purchased by the ICC in 1995. Gregory House is the only house in the organization that is expressly substance free. No tobacco, alcohol, or illicit drugs are allowed on the property. Gregory House has a maximum capacity of 29 members (by way of 13 single and 8 double capacity rooms) as of June 2008.»\n",
      "[4] «Kinnairdy Castle | Kinnairdy Castle is a tower house, having five storeys and a garret, two miles south of Aberchirder, Aberdeenshire, Scotland. The alternative name is Old Kinnairdy.»\n",
      "[5] «Kinnordy House | Kinnordy House (alternative spellings: Kynnordy, Kinardy, Kinnordie and Kinorde) is an estate house near Kirriemuir in Angus, Scotland. The first house was built in the 1680s, when Inverquharity Castle was vacated, however the current three-storey, towered and turreted structure dates from 1881, incorporating an 18th century wing and stables. The house was the birthplace of the noted geologist Charles Lyell, and is associated with his friend Charles Darwin.»\n",
      "\n",
      "Question: How many storeys are in the castle that David Gregory inherited?\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the answer. We know that Kinnairdy Castle is a tower house with five storeys.\n",
      "\n",
      "Answer: five\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "turbo.inspect_history(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Logic\n",
    "\n",
    "validation logic, which will simply require that:\n",
    "\n",
    "* The predicted answer (pred) matches the gold answer (example).\n",
    "* The retrieved context contains the gold answer.\n",
    "* None of the generated queries is rambling (i.e., none exceeds 100 characters in length).\n",
    "* None of the generated queries is roughly repeated (i.e., none is within 0.8 or higher F1 score of earlier queries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define your metric (wll pass to the teleprompter)\n",
    "\n",
    "def validate_context_and_answer_and_hops(example, pred, trace=None):\n",
    "    if not dspy.evaluate.answer_exact_match(example, pred): return False\n",
    "    if not dspy.evaluate.answer_passage_match(example, pred): return False\n",
    "\n",
    "    hops = [example.question] + [outputs.query for *_, outputs in trace  if 'query' in outputs]\n",
    "\n",
    "    if max([len(h) for h in hops]) > 100: return False\n",
    "    if any(dspy.evaluate.answer_exact_match_str(hops[idx], hops[:idx], frac=0.8) for idx in range(2, len(hops))): return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:00<00:00, 451.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 19 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer_and_hops)\n",
    "compiled_baleen = teleprompter.compile(SimplifiedBaleen(), teacher=SimplifiedBaleen(passages_per_hop=2), trainset=trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 50  (48.0): 100%|██████████| 50/50 [00:00<00:00, 2126.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 50  (48.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/taitlarson/.pyenv/versions/3.11.8/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:142: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a2137 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a2137 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a2137_row0_col0, #T_a2137_row0_col1, #T_a2137_row0_col2, #T_a2137_row0_col3, #T_a2137_row0_col4, #T_a2137_row0_col5, #T_a2137_row1_col0, #T_a2137_row1_col1, #T_a2137_row1_col2, #T_a2137_row1_col3, #T_a2137_row1_col4, #T_a2137_row1_col5, #T_a2137_row2_col0, #T_a2137_row2_col1, #T_a2137_row2_col2, #T_a2137_row2_col3, #T_a2137_row2_col4, #T_a2137_row2_col5, #T_a2137_row3_col0, #T_a2137_row3_col1, #T_a2137_row3_col2, #T_a2137_row3_col3, #T_a2137_row3_col4, #T_a2137_row3_col5, #T_a2137_row4_col0, #T_a2137_row4_col1, #T_a2137_row4_col2, #T_a2137_row4_col3, #T_a2137_row4_col4, #T_a2137_row4_col5 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a2137\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a2137_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_a2137_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_a2137_level0_col2\" class=\"col_heading level0 col2\" >gold_titles</th>\n",
       "      <th id=\"T_a2137_level0_col3\" class=\"col_heading level0 col3\" >context</th>\n",
       "      <th id=\"T_a2137_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_a2137_level0_col5\" class=\"col_heading level0 col5\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a2137_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a2137_row0_col0\" class=\"data row0 col0\" >Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
       "      <td id=\"T_a2137_row0_col1\" class=\"data row0 col1\" >no</td>\n",
       "      <td id=\"T_a2137_row0_col2\" class=\"data row0 col2\" >{'Cangzhou', 'Qionghai'}</td>\n",
       "      <td id=\"T_a2137_row0_col3\" class=\"data row0 col3\" >['Cangzhou | Cangzhou () is a prefecture-level city in eastern Hebei province, People\\'s Republic of China. At the 2010 census, Cangzhou\\'s built-up (\"or metro\") area...</td>\n",
       "      <td id=\"T_a2137_row0_col4\" class=\"data row0 col4\" >No</td>\n",
       "      <td id=\"T_a2137_row0_col5\" class=\"data row0 col5\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2137_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a2137_row1_col0\" class=\"data row1 col0\" >Who conducts the draft in which Marc-Andre Fleury was drafted to the Vegas Golden Knights for the 2017-18 season?</td>\n",
       "      <td id=\"T_a2137_row1_col1\" class=\"data row1 col1\" >National Hockey League</td>\n",
       "      <td id=\"T_a2137_row1_col2\" class=\"data row1 col2\" >{'2017 NHL Expansion Draft', '2017–18 Pittsburgh Penguins season'}</td>\n",
       "      <td id=\"T_a2137_row1_col3\" class=\"data row1 col3\" >['2017–18 Pittsburgh Penguins season | The 2017–18 Pittsburgh Penguins season will be the 51st season for the National Hockey League ice hockey team that was...</td>\n",
       "      <td id=\"T_a2137_row1_col4\" class=\"data row1 col4\" >National Hockey League</td>\n",
       "      <td id=\"T_a2137_row1_col5\" class=\"data row1 col5\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2137_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a2137_row2_col0\" class=\"data row2 col0\" >The Wings entered a new era, following the retirement of which Canadian retired professional ice hockey player and current general manager of the Tampa Bay...</td>\n",
       "      <td id=\"T_a2137_row2_col1\" class=\"data row2 col1\" >Steve Yzerman</td>\n",
       "      <td id=\"T_a2137_row2_col2\" class=\"data row2 col2\" >{'Steve Yzerman', '2006–07 Detroit Red Wings season'}</td>\n",
       "      <td id=\"T_a2137_row2_col3\" class=\"data row2 col3\" >['Steve Yzerman | Stephen Gregory \"Steve\" Yzerman ( ; born May 9, 1965) is a Canadian retired professional ice hockey player and current general manager...</td>\n",
       "      <td id=\"T_a2137_row2_col4\" class=\"data row2 col4\" >Steve Yzerman</td>\n",
       "      <td id=\"T_a2137_row2_col5\" class=\"data row2 col5\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2137_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a2137_row3_col0\" class=\"data row3 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
       "      <td id=\"T_a2137_row3_col1\" class=\"data row3 col1\" >the River Tyne</td>\n",
       "      <td id=\"T_a2137_row3_col2\" class=\"data row3 col2\" >{'Crichton Castle', 'Crichton Collegiate Church'}</td>\n",
       "      <td id=\"T_a2137_row3_col3\" class=\"data row3 col3\" >[\"Crichton Collegiate Church | Crichton Collegiate Church is situated about 0.6 mi south west of the hamlet of Crichton in Midlothian, Scotland. Crichton itself is...</td>\n",
       "      <td id=\"T_a2137_row3_col4\" class=\"data row3 col4\" >River Tyne</td>\n",
       "      <td id=\"T_a2137_row3_col5\" class=\"data row3 col5\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a2137_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a2137_row4_col0\" class=\"data row4 col0\" >In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?</td>\n",
       "      <td id=\"T_a2137_row4_col1\" class=\"data row4 col1\" >King Alfred the Great</td>\n",
       "      <td id=\"T_a2137_row4_col2\" class=\"data row4 col2\" >{'Æthelweard (son of Alfred)', 'Ealhswith'}</td>\n",
       "      <td id=\"T_a2137_row4_col3\" class=\"data row4 col3\" >[\"Æthelweard of East Anglia | Æthelweard (died 854) was a 9th-century king of East Anglia, the long-lived Anglo-Saxon kingdom which today includes the English counties...</td>\n",
       "      <td id=\"T_a2137_row4_col4\" class=\"data row4 col4\" >Alfred the Great</td>\n",
       "      <td id=\"T_a2137_row4_col5\" class=\"data row4 col5\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x102ececd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center; \n",
       "                    font-size: 16px; \n",
       "                    font-weight: bold; \n",
       "                    color: #555; \n",
       "                    margin: 10px 0;'>\n",
       "                    ... 45 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "48.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I skipped retrieval eval above but need to add it now to compare Balean implementations.\n",
    "\n",
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
    "evaluate_on_hotpotqa = Evaluate(devset=devset, num_threads=1, display_progress=True, display_table=5)\n",
    "\n",
    "# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\n",
    "metric = dspy.evaluate.answer_exact_match\n",
    "evaluate_on_hotpotqa(compiled_rag, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_passages_retrieved(example, pred, trace=None):\n",
    "    gold_titles = set(map(dspy.evaluate.normalize_text, example['gold_titles']))\n",
    "    found_titles = set(map(dspy.evaluate.normalize_text, [c.split(' | ')[0] for c in pred.context]))\n",
    "\n",
    "    return gold_titles.issubset(found_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncompiled_baleen_retrieval_score = eval_on_hotpot(uncompiled_b, metric=gold_passages_retrieved, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 25 / 50  (50.0): 100%|██████████| 50/50 [04:09<00:00,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25 / 50  (50.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7dbf7 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7dbf7 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7dbf7_row0_col0, #T_7dbf7_row0_col1, #T_7dbf7_row0_col2, #T_7dbf7_row0_col3, #T_7dbf7_row0_col4, #T_7dbf7_row0_col5, #T_7dbf7_row1_col0, #T_7dbf7_row1_col1, #T_7dbf7_row1_col2, #T_7dbf7_row1_col3, #T_7dbf7_row1_col4, #T_7dbf7_row1_col5, #T_7dbf7_row2_col0, #T_7dbf7_row2_col1, #T_7dbf7_row2_col2, #T_7dbf7_row2_col3, #T_7dbf7_row2_col4, #T_7dbf7_row2_col5, #T_7dbf7_row3_col0, #T_7dbf7_row3_col1, #T_7dbf7_row3_col2, #T_7dbf7_row3_col3, #T_7dbf7_row3_col4, #T_7dbf7_row3_col5, #T_7dbf7_row4_col0, #T_7dbf7_row4_col1, #T_7dbf7_row4_col2, #T_7dbf7_row4_col3, #T_7dbf7_row4_col4, #T_7dbf7_row4_col5 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7dbf7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7dbf7_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_7dbf7_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_7dbf7_level0_col2\" class=\"col_heading level0 col2\" >gold_titles</th>\n",
       "      <th id=\"T_7dbf7_level0_col3\" class=\"col_heading level0 col3\" >context</th>\n",
       "      <th id=\"T_7dbf7_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
       "      <th id=\"T_7dbf7_level0_col5\" class=\"col_heading level0 col5\" >gold_passages_retrieved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7dbf7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7dbf7_row0_col0\" class=\"data row0 col0\" >Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
       "      <td id=\"T_7dbf7_row0_col1\" class=\"data row0 col1\" >no</td>\n",
       "      <td id=\"T_7dbf7_row0_col2\" class=\"data row0 col2\" >{'Cangzhou', 'Qionghai'}</td>\n",
       "      <td id=\"T_7dbf7_row0_col3\" class=\"data row0 col3\" >['Cangzhou | Cangzhou () is a prefecture-level city in eastern Hebei province, People\\'s Republic of China. At the 2010 census, Cangzhou\\'s built-up (\"or metro\") area...</td>\n",
       "      <td id=\"T_7dbf7_row0_col4\" class=\"data row0 col4\" >No</td>\n",
       "      <td id=\"T_7dbf7_row0_col5\" class=\"data row0 col5\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7dbf7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7dbf7_row1_col0\" class=\"data row1 col0\" >Who conducts the draft in which Marc-Andre Fleury was drafted to the Vegas Golden Knights for the 2017-18 season?</td>\n",
       "      <td id=\"T_7dbf7_row1_col1\" class=\"data row1 col1\" >National Hockey League</td>\n",
       "      <td id=\"T_7dbf7_row1_col2\" class=\"data row1 col2\" >{'2017 NHL Expansion Draft', '2017–18 Pittsburgh Penguins season'}</td>\n",
       "      <td id=\"T_7dbf7_row1_col3\" class=\"data row1 col3\" >[\"2017 NHL Expansion Draft | The 2017 NHL Expansion Draft was an expansion draft conducted by the National Hockey League on June 18–20, 2017 to...</td>\n",
       "      <td id=\"T_7dbf7_row1_col4\" class=\"data row1 col4\" >National Hockey League</td>\n",
       "      <td id=\"T_7dbf7_row1_col5\" class=\"data row1 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7dbf7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7dbf7_row2_col0\" class=\"data row2 col0\" >The Wings entered a new era, following the retirement of which Canadian retired professional ice hockey player and current general manager of the Tampa Bay...</td>\n",
       "      <td id=\"T_7dbf7_row2_col1\" class=\"data row2 col1\" >Steve Yzerman</td>\n",
       "      <td id=\"T_7dbf7_row2_col2\" class=\"data row2 col2\" >{'Steve Yzerman', '2006–07 Detroit Red Wings season'}</td>\n",
       "      <td id=\"T_7dbf7_row2_col3\" class=\"data row2 col3\" >['Steve Yzerman | Stephen Gregory \"Steve\" Yzerman ( ; born May 9, 1965) is a Canadian retired professional ice hockey player and current general manager...</td>\n",
       "      <td id=\"T_7dbf7_row2_col4\" class=\"data row2 col4\" >Steve Yzerman</td>\n",
       "      <td id=\"T_7dbf7_row2_col5\" class=\"data row2 col5\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7dbf7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7dbf7_row3_col0\" class=\"data row3 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
       "      <td id=\"T_7dbf7_row3_col1\" class=\"data row3 col1\" >the River Tyne</td>\n",
       "      <td id=\"T_7dbf7_row3_col2\" class=\"data row3 col2\" >{'Crichton Castle', 'Crichton Collegiate Church'}</td>\n",
       "      <td id=\"T_7dbf7_row3_col3\" class=\"data row3 col3\" >[\"Crichton Collegiate Church | Crichton Collegiate Church is situated about 0.6 mi south west of the hamlet of Crichton in Midlothian, Scotland. Crichton itself is...</td>\n",
       "      <td id=\"T_7dbf7_row3_col4\" class=\"data row3 col4\" >River Tyne</td>\n",
       "      <td id=\"T_7dbf7_row3_col5\" class=\"data row3 col5\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7dbf7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7dbf7_row4_col0\" class=\"data row4 col0\" >In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?</td>\n",
       "      <td id=\"T_7dbf7_row4_col1\" class=\"data row4 col1\" >King Alfred the Great</td>\n",
       "      <td id=\"T_7dbf7_row4_col2\" class=\"data row4 col2\" >{'Æthelweard (son of Alfred)', 'Ealhswith'}</td>\n",
       "      <td id=\"T_7dbf7_row4_col3\" class=\"data row4 col3\" >['Æthelweard (son of Alfred) | Æthelweard (d. 920 or 922) was the younger son of King Alfred the Great and Ealhswith.', 'Æthelweard (historian) | Æthelweard...</td>\n",
       "      <td id=\"T_7dbf7_row4_col4\" class=\"data row4 col4\" >King Alfred the Great</td>\n",
       "      <td id=\"T_7dbf7_row4_col5\" class=\"data row4 col5\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b43aa350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center; \n",
       "                    font-size: 16px; \n",
       "                    font-weight: bold; \n",
       "                    color: #555; \n",
       "                    margin: 10px 0;'>\n",
       "                    ... 45 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compiled_baleen_retrieval_score = evaluate_on_hotpotqa(compiled_baleen, metric=gold_passages_retrieved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is wnere you'd print out the metrics and compare the two implementations.  Interesting we only compare retrieval metrics. worth a re-read"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
