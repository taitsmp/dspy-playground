{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "repo_path = '.'\n",
    "\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)\n",
    "\n",
    "# Set up the cache for this notebook\n",
    "os.environ[\"DSP_NOTEBOOK_CACHEDIR\"] = os.path.join(repo_path, 'cache')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources # Install the package if it's not installed\n",
    "if not \"dspy-ai\" in {pkg.key for pkg in pkg_resources.working_set}:\n",
    "    !pip install -U pip\n",
    "    !pip install dspy-ai\n",
    "    !pip install openai~=0.28.1\n",
    "    # !pip install -e $repo_path\n",
    "\n",
    "import dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# Read the configuration file\n",
    "config.read('config.ini')\n",
    "\n",
    "# Access the API key\n",
    "api_key = config['openai']['api_key']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a hosted server with COLBERT that includes wikipedia extracts. We'll use it for the \"retriever model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo = dspy.OpenAI(model='gpt-3.5-turbo', api_key=api_key)\n",
    "colbertv2_wiki17_abstracts = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "dspy.settings.configure(lm=turbo, rm=colbertv2_wiki17_abstracts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Here's the response from GPT-3.5 Turbo:\n",
      "The capital of California is Sacramento.\n"
     ]
    }
   ],
   "source": [
    "# prove that openai is working\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Make a call to GPT-3.5 Turbo to test the API key\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the capital of California?\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(\"Success! Here's the response from GPT-3.5 Turbo:\")\n",
    "    print(response.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How DSPy programming works\n",
    "\n",
    "#### A word on the workflow\n",
    "\n",
    "You can build your own DSPy programs for various tasks, e.g., question answering, information extraction, or text-to-SQL.\n",
    "\n",
    "Whatever the task, the general workflow is:\n",
    "\n",
    "1. **Collect a little bit of data.** Define examples of the inputs and outputs of your program (e.g., questions and their answers). This could just be a handful of quick examples you wrote down. If large datasets exist, the more the merrier!\n",
    "1. **Write your program.** Define the modules (i.e., sub-tasks) of your program and the way they should interact together to solve your task.\n",
    "1. **Define some validation logic.** What makes for a good run of your program? Maybe the answers need to have a certain length or stick to a particular format? Specify the logic that checks that.\n",
    "1. **Compile!** Ask DSPy to compile your program using your data. The compiler will use your data and validation logic to optimize your program (e.g., prompts and modules) so it's efficient and effective!\n",
    "1. **Iterate.** Repeat the process by improving your data, program, validation, or by using more advanced features of the DSPy compiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taitlarson/.pyenv/versions/3.11.8/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20, 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.datasets import HotPotQA\n",
    "\n",
    "# Load the dataset.\n",
    "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0)\n",
    "\n",
    "# Tell DSPy that the 'question' field is the input. Any other fields are labels and/or metadata.\n",
    "trainset = [x.with_inputs('question') for x in dataset.train]\n",
    "devset = [x.with_inputs('question') for x in dataset.dev]\n",
    "\n",
    "len(trainset), len(devset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSPy typically requires very minimal labeling. Whereas your pipeline may involve six or seven complex steps, **you only need labels for the initial question and the final answer**. DSPy will bootstrap any intermediate labels needed to support your pipeline. If you change your pipeline in any way, the data bootstrapped will change accordingly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: At My Window was released by which American singer-songwriter?\n",
      "Answer: John Townes Van Zandt\n"
     ]
    }
   ],
   "source": [
    "train_example = trainset[0]\n",
    "print(f\"Question: {train_example.question}\")\n",
    "print(f\"Answer: {train_example.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples in the dev set contain a third field, namely, `titles` of relevant Wikipedia articles. This is not essential but, for the sake of this intro, it'll help us get a sense of how well our programs are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n",
      "Answer: English\n",
      "Relevant Wikipedia Titles: {'Restaurant: Impossible', 'Robert Irvine'}\n"
     ]
    }
   ],
   "source": [
    "dev_example = devset[18]\n",
    "print(f\"Question: {dev_example.question}\")\n",
    "print(f\"Answer: {dev_example.answer}\")\n",
    "print(f\"Relevant Wikipedia Titles: {dev_example.gold_titles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring labels and valid outputs\n",
    "\n",
    "After loading the raw data, we'd applied x.with_inputs('question') to each example to tell DSPy that our input field in each example will be just `question`. Any other fields are labels or metadata that are not given to the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this dataset, training examples have input keys ['question'] and label keys ['answer']\n",
      "For this dataset, dev examples have input keys ['question'] and label keys ['answer', 'gold_titles']\n"
     ]
    }
   ],
   "source": [
    "print(f\"For this dataset, training examples have input keys {train_example.inputs().keys()} and label keys {train_example.labels().keys()}\")\n",
    "print(f\"For this dataset, dev examples have input keys {dev_example.inputs().keys()} and label keys {dev_example.labels().keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DSPy, we will maintain a clean separation between defining your modules in a **declarative way** and calling them in a **pipeline** to solve the task.\n",
    "\n",
    "## Signatures\n",
    "\n",
    "Every call to the LM in a DSPy program needs to have a Signature.\n",
    "\n",
    "A signature consists of three simple elements:\n",
    "\n",
    "* A minimal description of the **sub-task** the LM is supposed to solve.\n",
    "* A description of one or more **input fields** (e.g., input question) that will we will give to the LM.\n",
    "* A description of one or more **output fields** (e.g., the question's answer) that we will expect from the LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `BasicQA`, the docstring describes the sub-task here (i.e., answering questions). Each `InputField` or `OutputField` can optionally contain a description `desc` too. When it's not given, it's inferred from the field's name (e.g., `question`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictors\n",
    "\n",
    "A predictor is a module that knows how to use the LM to implement a signature. Importantly, predictors can **learn** to fit their behavior to the task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n",
      "Predicted Answer: American\n"
     ]
    }
   ],
   "source": [
    "# Define the predictor\n",
    "generate_answer = dspy.Predict(BasicQA)\n",
    "\n",
    "# call the predictor on some input\n",
    "pred = generate_answer(question=dev_example.question)\n",
    "\n",
    "# Print the input and the prediction.\n",
    "print(f\"Question: {dev_example.question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
